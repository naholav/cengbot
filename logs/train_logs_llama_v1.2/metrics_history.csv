loss,grad_norm,learning_rate,epoch,step
2.9732,1.4373481273651123,2.7272727272727273e-05,0.030551842658010312,10
2.5784,0.8654234409332275,5.757575757575758e-05,0.061103685316020624,20
1.8673,0.7174882888793945,8.787878787878789e-05,0.09165552797403094,30
1.4808,0.5051463842391968,0.0001181818181818182,0.12220737063204125,40
1.2922,0.6906870007514954,0.00014848484848484849,0.15275921329005154,50
1.2283,0.5682706236839294,0.0001787878787878788,0.18331105594806188,60
